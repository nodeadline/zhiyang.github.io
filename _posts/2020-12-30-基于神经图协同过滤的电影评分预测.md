---
title: 基于神经图协同过滤的电影评分推荐
tags: 推荐系统
---

如何学习user和item的向量表示是推荐系统的核心，无论是矩阵分解，还是深度学习都一般会利用已存在的特征进行Embedding表示。但是user-item之间的隐性交互信息并没有在编码的过程中表示出来，这样的嵌入表示无法充分实现协同过滤作用。

‘Neural Graph Collaborative Filtering’提出利用图网络将user-item的交互信息编码进embedding中，这样可以在图结构中学习嵌入表示，提升了embedding的表示能力，有助于让模型表达高维特征。

本次实验复现这一过程，并实现基于神经图协同过滤的电影评分推荐系统，
以下为参考论文及代码：

1. [Neural Graph Collaborative Filtering](https://arxiv.org/abs/1905.08108)，SIGIR 2019，神经图协同过滤
2. [论文源码](https://github.com/xiangwang1223/neural_graph_collaborative_filtering)，xiangwang1223
3. [基于神经图协同过滤的电影评分推荐源码](https://github.com/nodeadline/code/tree/main/NGCF-pytorch-master)，nodeadline

## 方法介绍

### 摘要

论文原理：在 user-item interaction graph 上使用 GNN 来学习 user 向量和item 向量，用户向量和项向量的内积来预测评分。
区别：

1. 大部分论文使用 GNN 只是学习 user 向量，这篇论文的 item 向量也是使用GNN学习的
2. 大部分论文是在知识图谱KG或者社交网络Social Network上使用GNN，这篇论文是在用户-项交互二部图上使用GNN

学习 users 和 items 的向量表示是现代推荐系统的核心。
从早期的矩阵分解到最近出现的基于深度学习的方法，现有的工作通常通过从描述用户(或项目)的现有特性(如ID和属性)映射来获得用户(或项目)的嵌入。
我们认为，这种方法的一个固有缺点是，隐藏在用户-项目交互中的协作信号没有在嵌入过程中编码。因此，由此产生的嵌入可能不足以捕获协作过滤效果。
在这项工作中，我们建议将用户-项目交互更具体地集成到嵌入过程中二部图结构。提出了一种新的推荐框架神经图协同过滤算法(NGCF)，该算法利用用户项图的结构，在用户项图上传播嵌入。这就导致了用户项图中高阶连通性的表达建模，有效地将协作信号显式地注入到嵌入过程中

### 模型简介

假设用户为u，项目为i，我们可以画出user-item的二部图，同时根据二部图可以将u1的高维连接表示出来，如下图所示。

![二部图](https://zhiyang-blog.oss-cn-beijing.aliyuncs.com/image/20210114203126.png)

``` markdown
上图展示了一个 user-item 的二部图及 u1 的高阶连接性。
u1 的高阶连接性表示 u1 通过长度大于 1 的路径连接到的节点。
例如，u1 通过长度 l=2 的路径连接到 u2 和 u3，这代表 u1 的 2 阶连接性；u1 通过长度 l=3 的路径连接到 i4，i5，这代表 u1 的 3 阶连接性。需要注意的是，虽然 i4 和 i5 都是 u1 的 3 阶邻居，但是 i4 可以通过更多的路径连接到 u1，所以 i4 与 u1 的相似度更高。
```

### 模型框架

对于整体的模型框架有三个主要的部分：

1. embedding layer：提供初始的user embedding 和 item embedding
2. multiple embedding propagation layers：通过注入高阶连接关系来细化嵌入
3. the prediction layer：通过整合多层嵌入来预测(u,i)

### embedding layer

$$
E=[\underbrace{e_{u_1},...,e_{u_N}}_{users embeddings},\underbrace{e_{i_1},...,e_{i_M}}_{item embeddings}]
$$

1. 用嵌入向量$e_u\in{R^d},e_i\in{R^d}$描述用户u,项目i,d表示嵌入大小。
2. E是user和item的初始embedding状态，维度为d。
3. 在传统的推荐系统中，比如矩阵分解，它会直接将embedding输入到交互层，并最终得到用户评分。

### embedding propagation layers

首先考虑单层的embedding propagation layers

#### first-order propagation

$$
m_{u \leftarrow i}=f\left(e_i,e_u,p_{u_i}\right)$$

其中,$m_{u \leftarrow i}$表示消息从项目i到用户u,f表示编码函数,它的输入为embedding $e_i$和embedding $e_u$,以及边(u,i)的衰减因子$p_{ui}$

其中函数f的公式如下：

$$
m_{u \leftarrow i}=\frac{1}{\sqrt{|N_u|{|N_i|}}}\left(W_1e_i+W_2(e_i\bigodot{e_u})\right)
$$

$W_1$ 和$W_2$是可训练权重矩阵，维度为d*d，Nu，Ni 表示用户 u 和项目 i 的第一跳邻居.
$$
\frac{1}{\sqrt{|N_u|{|N_i|}}}
$$
也就是衰减因子$p_{ui}$。

$$
\frac{1}{\sqrt{|N_u|{|N_i|}}}
$$
是拉普拉斯标准化，从表示学习的角度，反映了历史项目对用户偏好的贡献程度。从消息传递的角度来看，可以解释为折扣因子，因为所传播的消息应该随着路径长度而衰减。

在考虑信息嵌入时，不是只考虑了项目的影响，而且将 ei 和 eu 之间的相互作用额外编码到通过 ei⊙eu 传递的消息中。这使得消息依赖于 ei 和 eu 之间的亲和力，例如，从相似的项传递更多的消息。

通过上面的式子就可以进行消息传递，但是对于一个节点u，它连接着的结点i不仅仅只有一个，其他的节点也要将消息传递给节点u，最后节点u要将所有传递给它的消息进行合并。

$$
e^{(1)}_{u}=\text{LeakyRelu}\left(m_{u \leftarrow u}+\displaystyle\sum_{i \in N_u} m_{u \leftarrow i}\right)
$$
  
其中$N_u$是节点u连接的其他节点。

#### high-order propagetion

利用一阶连通性可以增强表示，所以作者通过叠加更多的嵌入传播层来探索高阶连通性信息。这种高阶连通性对于协同信号来估计用户和项目之间的关联评分是至关重要的。
当层数增加后，消息传递公式可以如下表示：

$$
\{^{m_{u \leftarrow i}^{(l)}=p_{u_i}\left(W^{(l)}_1 e^{(l-1)}_i+W^{(l)}_2(e^{(l-1)}_i \bigodot {e^{(l-1)}_u}) \right)}_{m_{u \leftarrow u}^{(l)}=W^{(l)}_1 e^{(l-1)}_u}
$$

消息合并的公式如下表示：

$$
e^{(l)}_{u}=\text{LeakyRelu}\left(m_{u \leftarrow u}^{(l)}+\displaystyle\sum_{i \in N_u} m_{u \leftarrow i}^{(l)}\right)
$$

其中右上角的$l$表示的是第$l$层。
下图表示的就是3层的embedding propagation layer，我们可以清楚的看到，在嵌入传播过程中可以捕捉到
$u_1 \leftarrow i_2 \leftarrow u_2\leftarrow i_4$ 等协同信号。

![多联通图](https://zhiyang-blog.oss-cn-beijing.aliyuncs.com/image/20210114203152.png)

以上，我们一直对单个节点的传播嵌入进行分析，一个节点的embedding是一个向量，那么一个图的embedding就是将所有节点的embedding放到一起形成一个矩阵，也是一个图的原始特征，我们用E来表示，用矩阵表示传播规则的公式如下所示：

$$
E^{(l)}=\text{LeakyRelu}\left((\zeta+I)E^{(l-1)}W^{(l)}_1+\zeta E^{(l-1)} \bigodot E^{(l-1)} W^{(l)}_2\right)
$$

$\zeta$ 是用户-项目图的拉普拉斯矩阵，
$E^{(l)} ∈ R^{(N+M)×dl}$ 是用户和项经过 $l$ 步嵌入传播后得到的表示，
I 表示一个单位矩阵

$$
\zeta=D^{-\frac{1}{2}} A D^{-\frac{1}{2}} \text{and} A=\left[\begin{matrix}0 &R \\R^T &0 \end{matrix}\right]
$$

$R\in{\text{R}^{N\times{M}}}$为用户-项目交互矩阵

0 为全 0 矩阵

A 为邻接矩阵，D 为对角度矩阵，其中第 t 个对角元素 $D_{tt} = |Nt|$，这样 $\zeta_{ui}$ 就等于之前的系数$p_{ui}$

### the prediction layer

经过L层的传播之后,我们得到了L个关于用户u的向量表达$e^1_u$,...,$e^{l}_u$,由于在不同层中获得的向量表示,是通过不同连接传递的消息，所以它们在反映用户偏好方面有不同的贡献,所以我们将这些向量表示串联起来,得到用户u的最终表示.

$$
{e^{*}_u}={e^{0}_u}||...||{e^{L}_u},{e^{*}_i}={e^{0}_i}||...||{e^{L}_i}
$$

其中||为串联操作。除了连接，其他聚合器也可以应用，如加权平均、最大池、LSTM。使用串联在于它的简单性，不需要学习额外的参数，而且已经被非常有效地证明了。
最后，我们进行内积来估计用户对目标产品的偏好

$$
\hat{y}_{NCGF}(u,i)={e^{*}_u}^T{e^{*}_i}
$$

NGCF框架的整体结构如下所示:

![框架图](https://zhiyang-blog.oss-cn-beijing.aliyuncs.com/image/20210114203214.png)

损失函数：考虑观察到的和未观察到的用户-项目交互之间的相对顺序。具体地说， BPR 损失函数假设用户引用的已观察到的交互作用应该比未观察到的交互作用具有更高的预测值

$$
Loss=\displaystyle\sum_{(u,i,j) \in O}{-ln{\sigma(\hat{y}_{u_i}-\hat{y}_{u_j})+{\lambda{||\theta||}^2_2}}}
$$

## 代码实现

由于采用的是movielens100k数据集，数据集中存在5折交叉验证数据，故在这里的数据预处理只是分别读取train，test数据，并处理格式。

```python
import pandas as pd
import sys
sys.path.extend(['E:\\zhiyangwang\\common\\NGCF-pytorch-master'])
from os import path
# load 100k data

path100k = path.dirname(__file__) + r'\1K'


def load100KRatingstrain(idx):
    df = pd.read_table(path100k+r'\u{0}.base'.format(idx),sep='\t',names=['userId','itemId','rating','timestamp'])#r'\'
    return df

def load100KRatingstest(idx):
    df = pd.read_table(path100k+r'\u{0}.test'.format(idx),sep='\t',names=['userId','itemId','rating','timestamp'])
    return df

def load100KItemSide():
    import codecs
    with codecs.open(path100k+'/u.item', 'r', 'utf-8', errors='ignore') as f:
        movies = pd.read_table(f, delimiter='|', header=None,names="itemId| movie title | release date | video release date | IMDb URL | unknown | Action | Adventure | Animation | Children's | Comedy | Crime | Documentary | Drama | Fantasy | Film-Noir | Horror | Musical | Mystery | Romance | Sci-Fi | Thriller | War | Western ".split('|'))
    return movies

def load100kUserSide():
    import codecs
    with codecs.open(path100k + '/u.user', 'r', 'utf-8', errors='ignore') as f:
        users = pd.read_table(f, delimiter='|', header=None,names="userId| age | gender | occupation | zip code".split('|'))
    return users
```

```python
from torch.utils.data import Dataset

# movielens 100k

class ML1K(Dataset):

    def __init__(self,rt):
        super(Dataset,self).__init__()
        self.uId = list(rt['userId'])
        self.iId = list(rt['itemId'])
        self.rt = list(rt['rating'])

    def __len__(self):
        return len(self.uId)

    def __getitem__(self, item):
        return (self.uId[item],self.iId[item],self.rt[item])
```

模型构建,SVD和NCF为常见的协同过滤算法，在这里作为对比实验，不详述：

```python
import torch
import torch.nn as nn
from torch.nn import Module
from scipy.sparse import coo_matrix
from scipy.sparse import vstack
from scipy import sparse
import numpy as np


# several models for recommendations

# RMSE
# SVD dim = 50 50 epoch RMSE = 0.931
# GNCF dim = 64 layer = [64,64,64] nn = [128,64,32,] 50 epoch RMSE = 0.916/RMSE =0.914
# NCF dim = 64 50 nn = [128,54,32] epoch 50 RMSE = 0.928

class SVD(Module):

    def __init__(self,userNum,itemNum,dim):
        super(SVD, self).__init__()
        self.uEmbd = nn.Embedding(userNum,dim)
        self.iEmbd = nn.Embedding(itemNum,dim)
        self.uBias = nn.Embedding(userNum,1)
        self.iBias = nn.Embedding(itemNum,1)
        self.overAllBias = nn.Parameter(torch.Tensor([0]))

    def forward(self, userIdx,itemIdx):
        uembd = self.uEmbd(userIdx)
        iembd = self.iEmbd(itemIdx)
        ubias = self.uBias(userIdx)
        ibias = self.iBias(itemIdx)

        biases = ubias + ibias + self.overAllBias
        prediction = torch.sum(torch.mul(uembd,iembd),dim=1) + biases.flatten()

        return prediction

class NCF(Module):

    def __init__(self,userNum,itemNum,dim,layers=[128,64,32,8]):
        super(NCF, self).__init__()
        self.uEmbd = nn.Embedding(userNum,dim)
        self.iEmbd = nn.Embedding(itemNum,dim)
        self.fc_layers = torch.nn.ModuleList()
        self.finalLayer = torch.nn.Linear(layers[-1],1)

        for From,To in zip(layers[:-1],layers[1:]):
            self.fc_layers.append(nn.Linear(From,To))

    def forward(self, userIdx,itemIdx):
        uembd = self.uEmbd(userIdx)
        iembd = self.iEmbd(itemIdx)
        embd = torch.cat([uembd, iembd], dim=1)
        x = embd
        for l in self.fc_layers:
            x = l(x)
            x = nn.ReLU()(x)

        prediction = self.finalLayer(x)
        return prediction.flatten()
```

GNN模块：其主要作用将item和user的编码信息整合到一起，通过拉普拉斯矩阵运算实现在高阶传播中融合高阶邻居的信息，并有助于高效对节点 Embedding 信息的更新。最终返回一个item和user的融合高阶邻居的信息的高阶节点表示。

```python
class GNNLayer(Module):

    def __init__(self,inF,outF):

        super(GNNLayer,self).__init__()
        self.inF = inF
        self.outF = outF
        self.linear = torch.nn.Linear(in_features=inF,out_features=outF)
        self.interActTransform = torch.nn.Linear(in_features=inF,out_features=outF)

    def forward(self, laplacianMat,selfLoop,features):
        # for GCF ajdMat is a (N+M) by (N+M) mat
        # laplacianMat L = D^-1(A)D^-1 # 拉普拉斯矩阵
        L1 = laplacianMat + selfLoop
        L2 = laplacianMat.cuda()
        L1 = L1.cuda()
        inter_feature = torch.sparse.mm(L2,features)
        inter_feature = torch.mul(inter_feature,features)

        inter_part1 = self.linear(torch.sparse.mm(L1,features))
        inter_part2 = self.interActTransform(torch.sparse.mm(L2,inter_feature))

        return inter_part1+inter_part2
```

GCF模型结构图预览：

```python
GCF(
  (uEmbd): Embedding(943, 80)
  (iEmbd): Embedding(1682, 80)
  (GNNlayers): ModuleList(
    (0): GNNLayer(
      (linear): Linear(in_features=80, out_features=80, bias=True)
      (interActTransform): Linear(in_features=80, out_features=80, bias=True)
    )
  )
  (leakyRelu): LeakyReLU(negative_slope=0.01)
  (transForm1): Linear(in_features=320, out_features=64, bias=True)
  (transForm2): Linear(in_features=64, out_features=32, bias=True)
  (transForm3): Linear(in_features=32, out_features=1, bias=True)
)
```

```python
class GCF(Module):

    def __init__(self,userNum,itemNum,rt,embedSize=100,layers=[100,80,50],useCuda=True):

        super(GCF,self).__init__()
        self.useCuda = useCuda
        self.userNum = userNum
        self.itemNum = itemNum
        self.uEmbd = nn.Embedding(userNum,embedSize)
        self.iEmbd = nn.Embedding(itemNum,embedSize)
        self.GNNlayers = torch.nn.ModuleList()
        self.LaplacianMat = self.buildLaplacianMat(rt) # sparse format
        self.leakyRelu = nn.LeakyReLU()
        self.selfLoop = self.getSparseEye(self.userNum+self.itemNum)

        self.transForm1 = nn.Linear(in_features=layers[-1]*(len(layers))*2,out_features=64)
        self.transForm2 = nn.Linear(in_features=64,out_features=32)
        self.transForm3 = nn.Linear(in_features=32,out_features=1)

        for From,To in zip(layers[:-1],layers[1:]):
            self.GNNlayers.append(GNNLayer(From,To))
```

构建用户和项目之间的二维关联图,也就是二部图

```python
    def getSparseEye(self,num):
        i = torch.LongTensor([[k for k in range(0,num)],[j for j in range(0,num)]])
        val = torch.FloatTensor([1]*num)
        return torch.sparse.FloatTensor(i,val)
```

构建拉普拉斯矩阵，实现用户和项目经过 $l$步嵌入传播后得到的表示,获得高阶表示

```python
    def buildLaplacianMat(self,rt):

        rt_item = rt['itemId'] + self.userNum
        uiMat = coo_matrix((rt['rating'], (rt['userId'], rt['itemId'])))

        uiMat_upperPart = coo_matrix((rt['rating'], (rt['userId'], rt_item)))
        uiMat = uiMat.transpose()
        uiMat.resize((self.itemNum, self.userNum + self.itemNum))

        A = sparse.vstack([uiMat_upperPart,uiMat])
        selfLoop = sparse.eye(self.userNum+self.itemNum)
        sumArr = (A>0).sum(axis=1)
        diag = list(np.array(sumArr.flatten())[0])
        diag = np.power(diag,-0.5)
        D = sparse.diags(diag)
        L = D * A * D
        L = sparse.coo_matrix(L)
        row = L.row
        col = L.col
        i = torch.LongTensor([row,col])
        data = torch.FloatTensor(L.data)
        SparseL = torch.sparse.FloatTensor(i,data)
        return SparseL
```

对用户和项目进行embeddings编码

```python
    def getFeatureMat(self):
        uidx = torch.LongTensor([i for i in range(self.userNum)])
        iidx = torch.LongTensor([i for i in range(self.itemNum)])
        if self.useCuda == True:
            uidx = uidx.cuda()
            iidx = iidx.cuda()

        userEmbd = self.uEmbd(uidx)
        itemEmbd = self.iEmbd(iidx)
        features = torch.cat([userEmbd,itemEmbd],dim=0)
        return features
```

合并用户和项目融合高阶邻居信息后更新的embedding，并通过transForms实现类似CNN中的dense操作，最终输出一个预测值

```python
    def forward(self,userIdx,itemIdx):

        itemIdx = itemIdx + self.userNum
        userIdx = list(userIdx.cpu().data)
        itemIdx = list(itemIdx.cpu().data)
        # gcf data propagation
        features = self.getFeatureMat()
        finalEmbd = features.clone()
        for gnn in self.GNNlayers:
            features = gnn(self.LaplacianMat,self.selfLoop,features)
            features = nn.ReLU()(features)
            finalEmbd = torch.cat([finalEmbd,features.clone()],dim=1)

        userEmbd = finalEmbd[userIdx]
        itemEmbd = finalEmbd[itemIdx]
        embd = torch.cat([userEmbd,itemEmbd],dim=1)

        embd = nn.ReLU()(self.transForm1(embd))
        embd = self.transForm2(embd)
        embd = self.transForm3(embd)
        prediction = embd.flatten()

        return prediction

if __name__ == '__main__':
    from toyDataset.loaddata import load100KRatings

    rt = load100KRatings()
    userNum = rt['userId'].max()
    itemNum = rt['itemId'].max()

    rt['userId'] = rt['userId'] - 1
    rt['itemId'] = rt['itemId'] - 1
    gcf = GCF(userNum,itemNum,rt)
```

五折交叉验证

```python
import torch
from torch import nn as nn
import sys
sys.path.extend(['E:\\zhiyangwang\\common\\NGCF-pytorch-master'])
from toyDataset.loaddata import load100KRatingstrain
from toyDataset.loaddata import load100KRatingstest
from scipy.sparse import coo_matrix
import pandas as pd
import numpy as np
from numpy import diag
from GraphNCF.GCFmodel import GCF
from torch.utils.data import DataLoader
from GraphNCF.dataPreprosessing import ML1K
from torch.utils.data import random_split
from torch.optim import Adam
from torch.nn import MSELoss
from GraphNCF.GCFmodel import SVD
from GraphNCF.GCFmodel import NCF

para = {
    'epoch':60,
    'lr':0.01,
    'batch_size':2048,
    'train':0.8
}
sum_mse=0
for idx in range(5):
    rt = load100KRatingstrain(idx+1)

    userNum = rt['userId'].max()
    itemNum = rt['itemId'].max()

    rt['userId'] = rt['userId'] - 1
    rt['itemId'] = rt['itemId'] - 1
    train = ML1K(rt)

    dl = DataLoader(train,batch_size=para['batch_size'],shuffle=True,pin_memory=True)
    model = GCF(userNum, itemNum, rt, 80, layers=[80,80,]).cuda()
    
    #print(model)

    # model = SVD(userNum,itemNum,50).cuda()
    # model = NCF(userNum,itemNum,64,layers=[128,64,32,16,8]).cuda()
    optim = Adam(model.parameters(), lr=para['lr'],weight_decay=0.001)
    lossfn = MSELoss()
    for i in range(para['epoch']):

        for id,batch in enumerate(dl):
            #print('epoch:',i,' batch:',id)
            optim.zero_grad()
            prediction = model(batch[0].cuda(), batch[1].cuda())
            loss = lossfn(batch[2].float().cuda(),prediction)
            loss.backward()
            optim.step()   
        print('epoch:',i,' loss:',loss)
    
    rt_test = load100KRatingstest(idx+1)

    userNum = rt_test['userId'].max()
    itemNum = rt_test['itemId'].max()

    rt_test['userId'] = rt_test['userId'] - 1
    rt_test['itemId'] = rt_test['itemId'] - 1
    test = ML1K(rt_test)

    testdl = DataLoader(test,batch_size=len(test),)
    for data in testdl:
        prediction = model(data[0].cuda(),data[1].cuda())

    lossfn = torch.nn.MSELoss(reduction='sum')
    rmse = lossfn(data[2].float().cuda(),prediction)/prediction.size(0)
    sum_mse=sum_mse+rmse
    print('MSE on cv_{0}_df:{1}'.format(idx+1,rmse))

print('Average MSE:{0}'.format(sum_mse/5))

```

运行结果：Average MSE:0.861227

![21/1/14/1](https://zhiyang-blog.oss-cn-beijing.aliyuncs.com/image/20210114214823.png)

![21/1/14/2](https://zhiyang-blog.oss-cn-beijing.aliyuncs.com/image/20210114214841.png)

![21/1/14/3](https://zhiyang-blog.oss-cn-beijing.aliyuncs.com/image/20210114214855.png)

![21/1/14/4](https://zhiyang-blog.oss-cn-beijing.aliyuncs.com/image/20210114214909.png)

![21/1/14/5](https://zhiyang-blog.oss-cn-beijing.aliyuncs.com/image/20210114214918.png)

### 总结
